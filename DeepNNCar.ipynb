{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DeepNNCar.ipynb","provenance":[],"collapsed_sections":["4KfGX3X6EiVe","F-BNQcKu_p-a","OyRuDGN8Ai_G"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xugPoY8IMybR"},"source":["# ReadMe\n","Author: Matthew P. Burruss, March 2020\n","\n","## Data Sets\n","\n","### Classification\n","For information on the classification data set (description, how to load it, model weights, etc.), please see this [google drive folder](https://drive.google.com/drive/folders/1fEWVY_rb2J0tkNtQ-605dRCMfXRpRwMF?usp=sharing). \n","\n","### Regression (Note: This notebook focuses soley on the classification task)\n","For information on the regression data set, please see this [google drive folder](https://drive.google.com/drive/folders/1Ryvlt5HWsLiEVZkYpX_aTivrlDuCcWIt?usp=sharing). \n","\n","## Model Weights (Classification)\n","Pre-trained RBF and regular softmax Keras weights can be found in this [google drive folder](https://drive.google.com/drive/folders/1A1Nw6qhxb4DLISh9ei7EHRE4jdKOe1VK?usp=sharing)..\n","\n","## Physical Attack\n","The code to perform the physical attack can be found in the utility function section below. The rest of the code loads the model and performs the attack as well as a few simple experiments.\n","\n","## Getting Started (Classification)\n","The only thing that needs changing is in the RBF section under the \"CHANGE ME\" subsection. The correct path to the data set and the location of the model weights will need to be updated.\n","\n","1. Navigate to this [google drive folder](https://drive.google.com/drive/folders/1fEWVY_rb2J0tkNtQ-605dRCMfXRpRwMF?usp=sharing) and create shortcuts in your own google drive for the data set (`deepnncar-classification-dataset.zip`) and any pre-trained weights you want to use.\n","\n","2. In the \"CHANGE ME\" subsecton of the \"RBF DAVEII: Classification with Rejection\" section below you need to change the paths to point to your data set wherever that might be located in the google drive system.\n","\n","5. Optional: Download the pre-trained weights for the DAVEII softmax classifier where the model can be loaded by invoking\n","```\n","softmax_model = DaveIIModel()\n","softmax_model.load(weights=os.path.join(MODEL_WEIGHT_LOC,'softmax_model.h5'))\n","```\n","where MODEL_WEIGHT_LOC is the path to the folder containing the weights in your google drive!\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vG1V9KimM2Ly"},"source":["# Connect to Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6lS5AMOxmnYI","executionInfo":{"status":"ok","timestamp":1610905073417,"user_tz":360,"elapsed":123307,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}},"outputId":"f1043074-e87c-4f82-b3b5-76f4388aebbd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","! pip3 install tensorflow==1.15"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Collecting tensorflow==1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 39kB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.19.5)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.32.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 54.4MB/s \n","\u001b[?25hCollecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 48.2MB/s \n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (51.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=b0ddafb02f69797a4881288b0eae1efdcc5cb439406d76a57d87de2b0e0ec4a5\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, keras-applications, tensorflow-estimator, gast, tensorflow\n","  Found existing installation: tensorboard 2.4.0\n","    Uninstalling tensorboard-2.4.0:\n","      Successfully uninstalled tensorboard-2.4.0\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow 2.4.0\n","    Uninstalling tensorflow-2.4.0:\n","      Successfully uninstalled tensorflow-2.4.0\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O8w4NpH6Dnai"},"source":["# RBF DAVEII: Classification with Rejection\n","The following code loads the partitioned DeepNNCar data set and performs the physical attack and re-creates a few of the experiments done in Matthew Burruss's Master's Thesis"]},{"cell_type":"markdown","metadata":{"id":"4KfGX3X6EiVe"},"source":["## CHANGE ME"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mxMJnxW5EfPM","executionInfo":{"status":"ok","timestamp":1610905073418,"user_tz":360,"elapsed":123298,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}},"outputId":"130b0546-64ca-43b7-ebd5-07096318bc83"},"source":["# Also update the location of the data set below if necessary\n","MODEL_WEIGHT_LOC ='/content/drive/My Drive/Colab Notebooks/pretrained_weights' # Path to your weight shortcuts (should be a folder containing the rbf_model.h5 and softmax_model.h5 files)\n","PATH_TO_REGRESSION_CSV = '/content/drive/My Drive/Colab Notebooks/deepnncar-regression-dataset.csv' # Path to the regression data set csv file shortcut if your interested in loading that\n","\n","%env PATH_TO_CLASSIFICATION_DATASET = /content/drive/My Drive/Colab Notebooks/deepnncar-classification-dataset.zip # path to the classification zip data set file"],"execution_count":2,"outputs":[{"output_type":"stream","text":["env: PATH_TO_CLASSIFICATION_DATASET=/content/drive/My Drive/Colab Notebooks/deepnncar-classification-dataset.zip # path to the classification zip data set file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gFp7gHuenfgP","executionInfo":{"status":"ok","timestamp":1610905073419,"user_tz":360,"elapsed":123298,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}}},"source":["# import os\n","# assert os.path.isfile(os.environ['PATH_TO_CLASSIFICATION_DATASET']),\\\n","#   print(\"File not found error\")\n","# %cd /content/\n","# ! cp -r \"${PATH_TO_CLASSIFICATION_DATASET}\" ./\n","# ! unzip deepnncar-classification-dataset.zip"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F-BNQcKu_p-a"},"source":["## Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAxj4fRnn8AA","executionInfo":{"status":"ok","timestamp":1610905078590,"user_tz":360,"elapsed":128464,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}},"outputId":"1a3750ad-e299-4d65-f1e8-e97abf9a476e"},"source":["from __future__ import print_function\n","!pip install keras==2.3.0\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","from keras.models import load_model,Model\n","import numpy as np\n","from keras import losses\n","import cv2\n","from sklearn.preprocessing import OneHotEncoder\n","import keras.backend as K\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization,Lambda, Input, ELU,Reshape\n","from keras.layers import Conv2D, MaxPooling2D,Input,AveragePooling2D,InputLayer,Convolution2D\n","from keras.models import Sequential\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, History\n","import math\n","from sklearn.metrics import mean_squared_error\n","from keras.engine.topology import Layer\n","from keras.initializers import RandomUniform, Initializer, Constant"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting keras==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n","\r\u001b[K     |▉                               | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 17.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 8.6MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.15.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (2.10.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.0.8)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed keras-2.3.0\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"OyRuDGN8Ai_G"},"source":["## Utility Functions"]},{"cell_type":"code","metadata":{"id":"iwZW6U23AiJa","executionInfo":{"status":"ok","timestamp":1610905078592,"user_tz":360,"elapsed":128465,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}}},"source":["def loadData(baseDir='/content/drive/My Drive/Colab Notebooks/deepnncar-classification-dataset',dataType='train'):\n","    assert dataType in ['train','test','val'],\\\n","        print('Not a valid type, must be train, test, or val')\n","    train_data_dir = os.path.join(baseDir,dataType)\n","    if (dataType=='test'):\n","        datagen = ImageDataGenerator(\n","            rescale = 1./255,\n","        )\n","        data_generator = datagen.flow_from_directory(\n","            train_data_dir,\n","            target_size = (66,200),\n","            batch_size = 16,\n","            class_mode = \"categorical\",\n","            shuffle=True)\n","        data_generator.batch_size = data_generator.samples\n","    else:\n","        datagen = ImageDataGenerator(\n","            rescale = 1./255,\n","            fill_mode = \"nearest\",\n","            zoom_range = 0.0,\n","            width_shift_range = 0.3,\n","            height_shift_range=0.3,\n","            rotation_range=0.0)\n","        data_generator = datagen.flow_from_directory(\n","            train_data_dir,\n","            target_size = (66,200),\n","            batch_size = 16,\n","            class_mode = \"categorical\",\n","            shuffle=True)\n","    return data_generator\n","\n","def PhysicalAttackLanes(alpha=1):\n","    baseDir = '/content/drive/My Drive/Colab Notebooks/deepnncar-classification-dataset/train/'\n","    numAttacksPerClass = 20\n","    classes = ['0','1','2','7','8','9']\n","    xadv = np.zeros((numAttacksPerClass*len(classes),66,200,3))\n","    x_clean = np.zeros((numAttacksPerClass*len(classes),66,200,3))\n","    y_label = np.zeros((numAttacksPerClass*len(classes)))\n","    y_adv = np.zeros((numAttacksPerClass*len(classes)))\n","    j = 0\n","    print('Creating physical attacks against e2e dave ii model')\n","    for c in classes:\n","        path = os.path.join(baseDir,c)\n","        images = os.listdir(path)\n","        image_name = np.random.choice(images,numAttacksPerClass,replace=False)\n","        cur_class = int(c)\n","        for i in range(image_name.shape[0]):\n","            img_base = cv2.imread(os.path.join(path,image_name[i])).astype(np.float32)\n","            badImage = np.copy(img_base)/255.\n","            if (cur_class < 1):\n","                pts = np.array([[0,36],[0,46],[178,34],[183,28]], np.int32)\n","            elif (cur_class < 4):\n","                pts = np.array([[0,36],[0,46],[178,34],[183,28]], np.int32)\n","            elif (cur_class < 9):\n","                pts = np.array([[10,28],[10,34],[200,46],[200,36]], np.int32)\n","            else:\n","                pts = np.array([[10,28],[10,34],[200,46],[200,36]], np.int32)\n","            cv2.fillPoly(badImage,[pts],(0,0,0))\n","            badImage = alpha*badImage + (1-alpha)*img_base/255.\n","            xadv[j] = badImage\n","            if (cur_class < 1):\n","                y_adv[j] = 9\n","            elif (cur_class < 4):\n","                y_adv[j] = 6\n","            elif (cur_class < 9):\n","                y_adv[j] = 3\n","            else:\n","                y_adv[j] = 0\n","            y_label[j] = cur_class\n","            x_clean[j] = img_base/255.\n","            j = j + 1\n","    y_label = keras.utils.to_categorical(y_label, 10)\n","    y_adv = keras.utils.to_categorical(y_adv, 10)\n","    return xadv,y_adv,y_label,x_clean"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KtqWccslA0dP"},"source":["## Define RBF Layer and SoftML Loss"]},{"cell_type":"code","metadata":{"id":"Vlw6NOdtA4Vc","executionInfo":{"status":"ok","timestamp":1610905078593,"user_tz":360,"elapsed":128462,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}}},"source":["class RBFLayer(Layer):\n","    def __init__(self, units, gamma, temp=None,**kwargs):\n","        super(RBFLayer, self).__init__(**kwargs)\n","        self.units = units\n","        self.gamma = K.cast_to_floatx(gamma)\n","        self.temp = temp\n","    def build(self, input_shape):\n","        self.mu = self.add_weight(name='mu',\n","                                  shape=(int(input_shape[1]), self.units),\n","                                  initializer=keras.initializers.RandomUniform(minval=-1, maxval=1, seed=1234),\n","                                  trainable=True)\n","        super(RBFLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        diff = K.expand_dims(inputs) - self.mu\n","        if (self.temp):\n","            diff = diff / self.temp\n","        l2 = K.sum(K.pow(diff, 2), axis=1)\n","        res = K.exp(0.0)*l2\n","        return res\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.units)\n","\n","    def get_config(self):\n","        # have to define get_config to be able to use model_from_json\n","        config = {\n","            'units': self.units,\n","            'gamma': self.gamma\n","        }\n","        base_config = super(RBFLayer, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))\n","\n","\n","# this is a helper function\n","def softargmax(x,beta=1e10):\n","    \"\"\"\n","    Perform argmax in a differential manner\n","    :param x: An array with the original inputs. `x` is expected to have spatial dimensions.\n","    :type x: `np.ndarray`\n","    :param beta: A large number to approximate argmax(`x`)\n","    :type y: float\n","    :return: argmax of tensor\n","    :rtype: `tensorflow.python.framework.ops.Tensor`\n","    \"\"\"\n","    x = tf.convert_to_tensor(x)\n","    x_range = tf.range(10)\n","    x_range = tf.dtypes.cast(x_range,tf.float32)\n","    return tf.reduce_sum(tf.nn.softmax(x*beta) * x_range, axis=1)\n","\n","RBF_LAMBDA = 0.5\n","def RBF_Soft_Loss(y_true,y_pred):\n","    lam = RBF_LAMBDA\n","    indices = softargmax(y_true)\n","    indices = tf.dtypes.cast(indices,tf.int32)\n","    y_pred = tf.dtypes.cast(y_pred,tf.float32)\n","    y_true = tf.dtypes.cast(y_true,tf.float32)\n","    row_ind = K.arange(K.shape(y_true)[0])\n","    full_indices = tf.stack([row_ind,indices],axis=1)\n","    d = tf.gather_nd(y_pred,full_indices)\n","    y_pred = K.log(1+ K.exp(lam - y_pred))\n","    S = K.sum(y_pred,axis=1) - K.log(1+K.exp(lam-d))\n","    y = K.sum(d + S)\n","    return y\n","\n","def DistanceMetric(y_true,y_pred):\n","    e  = K.equal(K.argmax(y_true,axis=1),K.argmin(y_pred,axis=1))\n","    s = tf.reduce_sum(tf.cast(e, tf.float32))\n","    n = tf.cast(K.shape(y_true)[0],tf.float32)\n","    return s/n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ptpqj9o7__IY"},"source":["## Define DAVEII Model"]},{"cell_type":"code","metadata":{"id":"I9ntU3yPACjJ","executionInfo":{"status":"ok","timestamp":1610905078823,"user_tz":360,"elapsed":128691,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}}},"source":["class DaveIIModel():\n","    def __init__(self,anomalyDetector=False):\n","        self.input_size = (66, 200, 3)\n","        self.num_classes = 10\n","        self.isAnomalyDetector = anomalyDetector\n","        model = Sequential()\n","        input1= Input(shape=(66,200,3), name='image')\n","        steer_inp = BatchNormalization(epsilon=0.001, axis=-1,momentum=0.99)(input1)\n","        layer1 = Conv2D(24, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(steer_inp)\n","        layer2 = Conv2D(36, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(layer1)\n","        layer3 = Conv2D(48, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(layer2)\n","        layer4 = Conv2D(64, (3, 3), padding=\"valid\", strides=(1, 1), activation=\"relu\")(layer3)\n","        layer5 = Conv2D(64, (3, 3), padding=\"valid\", strides=(1, 1))(layer4) # add relu for old time sake\n","        layer6 = Flatten()(layer5)\n","        if(anomalyDetector):\n","            layer7 = Activation('tanh')(layer6)\n","            prediction = RBFLayer(10,0.5)(layer7)\n","            model=Model(inputs=input1, outputs=prediction)\n","            model.summary()\n","            model.compile(loss=RBF_Soft_Loss,optimizer=keras.optimizers.Adam(),metrics=[DistanceMetric])\n","        else:\n","            layer6 = Activation('relu')(layer6) # remove me for old time sake\n","            layer7 = Dense(1164, activation='relu')(layer6)\n","            layer8 = Dense(100, activation='relu')(layer7)\n","            layer9 = Dense(50, activation='relu')(layer8)\n","            layer10 = Dense(10, activation='relu')(layer9)\n","            prediction = Dense(10, name='predictions',activation=\"softmax\")(layer10)\n","            model=Model(inputs=input1, outputs=prediction)\n","            model.summary()\n","            model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n","        self.model = model\n","\n","    def predict(self,X):\n","        predictions = self.model.predict(X)\n","        if (self.isAnomalyDetector):\n","            lam = RBF_LAMBDA\n","            Ok = np.exp(-1*predictions)\n","            top = Ok*(1+np.exp(lam)*Ok)\n","            bottom = np.prod(1+np.exp(lam)*Ok,axis=1)\n","            predictions = np.divide(top.T,bottom).T\n","        return predictions\n","\n","    def getInputSize(self):\n","        return self.input_size\n","\n","    def getNumberClasses(self):\n","        return self.num_classes\n","\n","    def train(self,train_data_generator,validation_data_generator,saveTo,epochs=10,class_weight=None):\n","\n","        if (self.isAnomalyDetector):\n","            checkpoint = ModelCheckpoint(saveTo, monitor='DistanceMetric', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\n","        else:\n","            checkpoint = ModelCheckpoint(saveTo, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","        self.model.fit_generator(\n","            train_data_generator,\n","            steps_per_epoch = math.ceil(train_data_generator.samples/train_data_generator.batch_size),\n","            epochs = epochs,\n","            validation_data = validation_data_generator,\n","            validation_steps = math.ceil(validation_data_generator.samples/validation_data_generator.batch_size),\n","            callbacks = [checkpoint],\n","            class_weight=class_weight)\n","\n","    def train_data(self,X,Y,saveTo,epochs=10,class_weight=None):\n","        if (self.isAnomalyDetector):\n","            checkpoint = ModelCheckpoint(saveTo, monitor='DistanceMetric', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\n","        else:\n","            checkpoint = ModelCheckpoint(saveTo, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","        self.model.fit(X, Y,\n","                batch_size=8,\n","                epochs=epochs,\n","                verbose=1,\n","                callbacks=[checkpoint],\n","                shuffle=True,\n","                class_weight=class_weight)\n","\n","    def load(self,weights):\n","        if (self.isAnomalyDetector):\n","            self.model = load_model(weights, custom_objects={'RBFLayer': RBFLayer,'DistanceMetric':DistanceMetric,'RBF_Soft_Loss':RBF_Soft_Loss})\n","        else:\n","            self.model = load_model(weights)\n","\n","    def evaluate(self,X,Y):\n","        predictions = self.predict(X)\n","        accuracy = np.sum(np.argmax(predictions,axis=1) == np.argmax(Y, axis=1)) / len(Y)\n","        print('The accuracy of the model: ', accuracy)\n","        mse = mean_squared_error(np.argmax(Y, axis=1),np.argmax(predictions,axis=1))\n","        print('MSE of model: ', mse)\n","        print('Number of samples: ', len(Y))\n","    \n","    def evaluate_with_reject(self,X,Y):\n","        predictions = self.predict_with_reject(X)\n","        accuracy = np.sum(np.argmax(predictions,axis=1) == np.argmax(Y, axis=1)) / len(Y)\n","        print('The accuracy of the model: ', accuracy)\n","        mse = mean_squared_error(np.argmax(Y, axis=1),np.argmax(predictions,axis=1))\n","        print('MSE of model: ', mse)\n","        print('Number of samples: ', len(Y))\n","    \n","    def predict_with_reject(self,X):\n","        assert self.isAnomalyDetector, \\\n","            print('Cannot reject a softmax classifier')\n","        predictions = self.model.predict(X)\n","        lam = RBF_LAMBDA\n","        Ok = np.exp(-1*predictions)\n","        bottom = np.prod(1+np.exp(lam)*Ok,axis=1)\n","        reject = 1.0/bottom\n","        top = Ok*(1+np.exp(lam)*Ok)\n","        predictions = np.divide(top.T,bottom).T\n","        predictions = np.concatenate((predictions,np.expand_dims(reject,axis=1)),axis=1)\n","        return predictions\n","    \n","    def reject(self,X):\n","        assert self.isAnomalyDetector, \\\n","            print('Cannot reject a softmax classifier')\n","        predictions = self.model.predict(X)\n","        lam = RBF_LAMBDA\n","        Ok = np.exp(-1*predictions)\n","        bottom = np.prod(1+np.exp(lam)*Ok,axis=1)\n","        return 1.0/bottom\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"UMIXBxNnTisM","executionInfo":{"status":"ok","timestamp":1610905079030,"user_tz":360,"elapsed":128896,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}}},"source":["# Hunter 2021\n","class DaveIIModel2():\n","    def __init__(self,anomalyDetector=False):\n","        self.input_size = (66, 200, 3)\n","        self.num_classes = 10\n","        self.isAnomalyDetector = anomalyDetector\n","        model = Sequential()\n","        input1= Input(shape=(66,200,3), name='image')\n","        steer_inp = BatchNormalization(epsilon=0.001, axis=-1,momentum=0.99)(input1)\n","        layer1 = Conv2D(24, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(steer_inp)\n","        layer2 = Conv2D(36, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(layer1)\n","        layer3 = Conv2D(48, (5, 5), padding=\"valid\", strides=(2, 2), activation=\"relu\")(layer2)\n","        layer4 = Conv2D(64, (3, 3), padding=\"valid\", strides=(1, 1), activation=\"relu\")(layer3)\n","        layer5 = Conv2D(64, (3, 3), padding=\"valid\", strides=(1, 1))(layer4) # add relu for old time sake\n","        layer6 = Flatten()(layer5)\n","        if(anomalyDetector):\n","            layer7 = Activation('tanh')(layer6)\n","            prediction = RBFLayer(10,0.5)(layer7)\n","            model=Model(inputs=input1, outputs=prediction)\n","            model.summary()\n","            my_metric = DistanceMetric\n","            my_loss = RBF_Soft_Loss\n","            model.compile(loss=my_loss,optimizer=keras.optimizers.Adam(),metrics=[my_metric])\n","        else:\n","            layer6 = Activation('relu')(layer6) # remove me for old time sake\n","            layer7 = Dense(1164, activation='relu')(layer6)\n","            layer8 = Dense(100, activation='relu')(layer7)\n","            layer9 = Dense(50, activation='relu')(layer8)\n","            layer10 = Dense(10, activation='relu')(layer9)\n","            prediction = Dense(10, name='predictions',activation=\"softmax\")(layer10)\n","            model=Model(inputs=input1, outputs=prediction)\n","            model.summary()\n","            model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n","        self.model = model\n","\n","    def predict(self,X):\n","        predictions = self.model.predict(X)\n","        if (self.isAnomalyDetector):\n","            lam = RBF_LAMBDA\n","            Ok = np.exp(-1*predictions)\n","            top = Ok*(1+np.exp(lam)*Ok)\n","            bottom = np.prod(1+np.exp(lam)*Ok,axis=1)\n","            predictions = np.divide(top.T,bottom).T\n","        return predictions\n","\n","    def getInputSize(self):\n","        return self.input_size\n","\n","    def getNumberClasses(self):\n","        return self.num_classes\n","\n","    def train(self,train_data_generator,validation_data_generator,saveTo,epochs=10,class_weight=None):\n","\n","        if (self.isAnomalyDetector):\n","            checkpoint = ModelCheckpoint(saveTo, monitor='DistanceMetric', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\n","        else:\n","            checkpoint = ModelCheckpoint(saveTo, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","        self.model.fit_generator(\n","            train_data_generator,\n","            steps_per_epoch = math.ceil(train_data_generator.samples/train_data_generator.batch_size),\n","            epochs = epochs,\n","            validation_data = validation_data_generator,\n","            validation_steps = math.ceil(validation_data_generator.samples/validation_data_generator.batch_size),\n","            callbacks = [checkpoint],\n","            class_weight=class_weight)\n","\n","    def train_data(self,X,Y,saveTo,epochs=10,class_weight=None):\n","        if (self.isAnomalyDetector):\n","            checkpoint = ModelCheckpoint(saveTo, monitor='DistanceMetric', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\n","        else:\n","            checkpoint = ModelCheckpoint(saveTo, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","        self.model.fit(X, Y,\n","                batch_size=8,\n","                epochs=epochs,\n","                verbose=1,\n","                callbacks=[checkpoint],\n","                shuffle=True,\n","                class_weight=class_weight)\n","\n","    def load(self,weights):\n","        if (self.isAnomalyDetector):\n","            self.model = load_model(weights, custom_objects={'RBFLayer': RBFLayer,'DistanceMetric':DistanceMetric,'RBF_Soft_Loss':RBF_Soft_Loss})\n","        else:\n","            self.model = load_model(weights)\n","\n","    def evaluate(self,X,Y):\n","        predictions = self.predict(X)\n","        accuracy = np.sum(np.argmax(predictions,axis=1) == np.argmax(Y, axis=1)) / len(Y)\n","        print('The accuracy of the model: ', accuracy)\n","        mse = mean_squared_error(np.argmax(Y, axis=1),np.argmax(predictions,axis=1))\n","        print('MSE of model: ', mse)\n","        print('Number of samples: ', len(Y))\n","    \n","    def evaluate_with_reject(self,X,Y):\n","        predictions = self.predict_with_reject(X)\n","        accuracy = np.sum(np.argmax(predictions,axis=1) == np.argmax(Y, axis=1)) / len(Y)\n","        print('The accuracy of the model: ', accuracy)\n","        mse = mean_squared_error(np.argmax(Y, axis=1),np.argmax(predictions,axis=1))\n","        print('MSE of model: ', mse)\n","        print('Number of samples: ', len(Y))\n","    \n","    def predict_with_reject(self,X):\n","        assert self.isAnomalyDetector, \\\n","            print('Cannot reject a softmax classifier')\n","        predictions = self.model.predict(X)\n","        lam = RBF_LAMBDA\n","        Ok = np.exp(-1*predictions)\n","        bottom = np.prod(1+np.exp(lam)*Ok,axis=1)\n","        reject = 1.0/bottom\n","        top = Ok*(1+np.exp(lam)*Ok)\n","        predictions = np.divide(top.T,bottom).T\n","        predictions = np.concatenate((predictions,np.expand_dims(reject,axis=1)),axis=1)\n","        return predictions\n","    \n","    def reject(self,X):\n","        assert self.isAnomalyDetector, \\\n","            print('Cannot reject a softmax classifier')\n","        predictions = self.model.predict(X)\n","        lam = RBF_LAMBDA\n","        Ok = np.exp(-1*predictions)\n","        bottom = np.prod(1+np.exp(lam)*Ok,axis=1)\n","        return 1.0/bottom\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tl98cucABaKf"},"source":["## Load the partitioned data into training, validation, and create physical attack"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bWMdixP7oOaG","executionInfo":{"status":"ok","timestamp":1610905432386,"user_tz":360,"elapsed":482246,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}},"outputId":"10e82d36-782d-4a10-c2c6-6368971d2456"},"source":["train_data_generator = loadData(dataType='train')\n","validation_data_generator = loadData(dataType='val')\n","test_data_generator = loadData(dataType='test')\n","x_test,y_test = test_data_generator.next()\n","print('Number of test data',y_test.shape[0])\n","# xadv,yadv,y_true,x_clean = PhysicalAttackLanes()\n","# print('Number of attacks',yadv.shape[0])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 4196 images belonging to 10 classes.\n","Found 896 images belonging to 10 classes.\n","Found 908 images belonging to 10 classes.\n","Number of test data 908\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O66u-jG0Buyg"},"source":["## Load the DAVE II Models"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZEvbYnnBzFz","outputId":"c0e6d68c-b4f1-4d24-ba52-dc15e84729d9"},"source":["# SOFTMAX MODEL CLEAN\n","# softmax_model = DaveIIModel()\n","# softmax_model.load(weights=os.path.join(MODEL_WEIGHT_LOC,'softmax_model.h5'))\n","# K.set_value(softmax_model.model.optimizer.lr,0.0001)\n","# softmax_model.train(train_data_generator,validation_data_generator,saveTo=os.path.join(MODEL_WEIGHT_LOC,'softmax_model.h5'),epochs=100)\n","# print('Loaded softmax clean model...')\n","\n","# ANOMALY DETECTOR CLEAN\n","rbf_model = DaveIIModel(anomalyDetector=True)\n","# rbf_model.load(weights=os.path.join(MODEL_WEIGHT_LOC,'rbf_model_original.h5'))\n","K.set_value(rbf_model.model.optimizer.lr,0.0001)\n","rbf_model.train(train_data_generator,validation_data_generator,saveTo=os.path.join(MODEL_WEIGHT_LOC,'rbf_model.h5'),epochs=100)\n","print('loaded anomaly clean model...')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","image (InputLayer)           (None, 66, 200, 3)        0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 66, 200, 3)        12        \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 31, 98, 24)        1824      \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 14, 47, 36)        21636     \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 5, 22, 48)         43248     \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 3, 20, 64)         27712     \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 1, 18, 64)         36928     \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 1152)              0         \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 1152)              0         \n","_________________________________________________________________\n","rbf_layer_2 (RBFLayer)       (None, 10)                11520     \n","=================================================================\n","Total params: 142,880\n","Trainable params: 142,874\n","Non-trainable params: 6\n","_________________________________________________________________\n","Epoch 1/100\n","263/263 [==============================] - 1663s 6s/step - loss: 5878.1458 - DistanceMetric: 0.1602 - val_loss: 5677.9722 - val_DistanceMetric: 0.1518\n","\n","Epoch 00001: DistanceMetric improved from -inf to 0.16017, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 2/100\n","263/263 [==============================] - 23s 89ms/step - loss: 5482.4867 - DistanceMetric: 0.2357 - val_loss: 5304.6294 - val_DistanceMetric: 0.2455\n","\n","Epoch 00002: DistanceMetric improved from 0.16017 to 0.23574, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 3/100\n","263/263 [==============================] - 24s 91ms/step - loss: 5125.3661 - DistanceMetric: 0.2552 - val_loss: 5009.9355 - val_DistanceMetric: 0.2567\n","\n","Epoch 00003: DistanceMetric improved from 0.23574 to 0.25523, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 4/100\n","263/263 [==============================] - 24s 91ms/step - loss: 4789.4559 - DistanceMetric: 0.2754 - val_loss: 4665.1074 - val_DistanceMetric: 0.2835\n","\n","Epoch 00004: DistanceMetric improved from 0.25523 to 0.27543, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 5/100\n","263/263 [==============================] - 25s 94ms/step - loss: 4478.7228 - DistanceMetric: 0.2949 - val_loss: 4357.4868 - val_DistanceMetric: 0.3058\n","\n","Epoch 00005: DistanceMetric improved from 0.27543 to 0.29491, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 6/100\n","263/263 [==============================] - 24s 90ms/step - loss: 4186.9066 - DistanceMetric: 0.3035 - val_loss: 4009.5620 - val_DistanceMetric: 0.3214\n","\n","Epoch 00006: DistanceMetric improved from 0.29491 to 0.30347, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 7/100\n","263/263 [==============================] - 23s 88ms/step - loss: 3909.1123 - DistanceMetric: 0.3232 - val_loss: 3751.9424 - val_DistanceMetric: 0.3259\n","\n","Epoch 00007: DistanceMetric improved from 0.30347 to 0.32319, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 8/100\n","263/263 [==============================] - 22s 85ms/step - loss: 3646.6457 - DistanceMetric: 0.3287 - val_loss: 3523.3916 - val_DistanceMetric: 0.3371\n","\n","Epoch 00008: DistanceMetric improved from 0.32319 to 0.32866, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 9/100\n","263/263 [==============================] - 23s 87ms/step - loss: 3400.6368 - DistanceMetric: 0.3284 - val_loss: 3244.1650 - val_DistanceMetric: 0.3504\n","\n","Epoch 00009: DistanceMetric did not improve from 0.32866\n","Epoch 10/100\n","263/263 [==============================] - 23s 87ms/step - loss: 3168.4940 - DistanceMetric: 0.3325 - val_loss: 3079.4214 - val_DistanceMetric: 0.3237\n","\n","Epoch 00010: DistanceMetric improved from 0.32866 to 0.33246, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 11/100\n","263/263 [==============================] - 23s 87ms/step - loss: 2946.1450 - DistanceMetric: 0.3322 - val_loss: 2819.0181 - val_DistanceMetric: 0.3304\n","\n","Epoch 00011: DistanceMetric did not improve from 0.33246\n","Epoch 12/100\n","263/263 [==============================] - 22s 85ms/step - loss: 2738.6853 - DistanceMetric: 0.3310 - val_loss: 2582.9546 - val_DistanceMetric: 0.3493\n","\n","Epoch 00012: DistanceMetric did not improve from 0.33246\n","Epoch 13/100\n","263/263 [==============================] - 22s 84ms/step - loss: 2541.0114 - DistanceMetric: 0.3479 - val_loss: 2518.1396 - val_DistanceMetric: 0.3527\n","\n","Epoch 00013: DistanceMetric improved from 0.33246 to 0.34791, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 14/100\n","263/263 [==============================] - 23s 86ms/step - loss: 2354.4604 - DistanceMetric: 0.3379 - val_loss: 2262.8052 - val_DistanceMetric: 0.3583\n","\n","Epoch 00014: DistanceMetric did not improve from 0.34791\n","Epoch 15/100\n","263/263 [==============================] - 22s 85ms/step - loss: 2179.2563 - DistanceMetric: 0.3334 - val_loss: 2117.7969 - val_DistanceMetric: 0.3426\n","\n","Epoch 00015: DistanceMetric did not improve from 0.34791\n","Epoch 16/100\n","263/263 [==============================] - 22s 85ms/step - loss: 2012.6220 - DistanceMetric: 0.3370 - val_loss: 1879.2178 - val_DistanceMetric: 0.3315\n","\n","Epoch 00016: DistanceMetric did not improve from 0.34791\n","Epoch 17/100\n","263/263 [==============================] - 23s 87ms/step - loss: 1855.1466 - DistanceMetric: 0.3446 - val_loss: 1775.5916 - val_DistanceMetric: 0.3605\n","\n","Epoch 00017: DistanceMetric did not improve from 0.34791\n","Epoch 18/100\n","263/263 [==============================] - 23s 86ms/step - loss: 1707.5960 - DistanceMetric: 0.3339 - val_loss: 1645.5233 - val_DistanceMetric: 0.3147\n","\n","Epoch 00018: DistanceMetric did not improve from 0.34791\n","Epoch 19/100\n","263/263 [==============================] - 24s 89ms/step - loss: 1568.5530 - DistanceMetric: 0.3398 - val_loss: 1559.2869 - val_DistanceMetric: 0.3426\n","\n","Epoch 00019: DistanceMetric did not improve from 0.34791\n","Epoch 20/100\n","263/263 [==============================] - 22s 85ms/step - loss: 1437.8262 - DistanceMetric: 0.3222 - val_loss: 1329.4528 - val_DistanceMetric: 0.3158\n","\n","Epoch 00020: DistanceMetric did not improve from 0.34791\n","Epoch 21/100\n","263/263 [==============================] - 22s 85ms/step - loss: 1316.3249 - DistanceMetric: 0.3263 - val_loss: 1332.3726 - val_DistanceMetric: 0.3270\n","\n","Epoch 00021: DistanceMetric did not improve from 0.34791\n","Epoch 22/100\n","263/263 [==============================] - 22s 84ms/step - loss: 1201.4798 - DistanceMetric: 0.3246 - val_loss: 1075.5247 - val_DistanceMetric: 0.3281\n","\n","Epoch 00022: DistanceMetric did not improve from 0.34791\n","Epoch 23/100\n","263/263 [==============================] - 22s 83ms/step - loss: 1093.2305 - DistanceMetric: 0.3356 - val_loss: 997.3791 - val_DistanceMetric: 0.3270\n","\n","Epoch 00023: DistanceMetric did not improve from 0.34791\n","Epoch 24/100\n","263/263 [==============================] - 22s 83ms/step - loss: 993.6913 - DistanceMetric: 0.3194 - val_loss: 926.5142 - val_DistanceMetric: 0.3304\n","\n","Epoch 00024: DistanceMetric did not improve from 0.34791\n","Epoch 25/100\n","263/263 [==============================] - 22s 84ms/step - loss: 899.6713 - DistanceMetric: 0.3251 - val_loss: 880.5576 - val_DistanceMetric: 0.3092\n","\n","Epoch 00025: DistanceMetric did not improve from 0.34791\n","Epoch 26/100\n","263/263 [==============================] - 22s 83ms/step - loss: 812.3735 - DistanceMetric: 0.3194 - val_loss: 739.5920 - val_DistanceMetric: 0.3248\n","\n","Epoch 00026: DistanceMetric did not improve from 0.34791\n","Epoch 27/100\n","263/263 [==============================] - 22s 83ms/step - loss: 731.5021 - DistanceMetric: 0.3291 - val_loss: 820.2266 - val_DistanceMetric: 0.3371\n","\n","Epoch 00027: DistanceMetric did not improve from 0.34791\n","Epoch 28/100\n","263/263 [==============================] - 22s 85ms/step - loss: 656.6774 - DistanceMetric: 0.3239 - val_loss: 623.7153 - val_DistanceMetric: 0.3203\n","\n","Epoch 00028: DistanceMetric did not improve from 0.34791\n","Epoch 29/100\n","263/263 [==============================] - 22s 83ms/step - loss: 587.8513 - DistanceMetric: 0.3218 - val_loss: 581.9385 - val_DistanceMetric: 0.3404\n","\n","Epoch 00029: DistanceMetric did not improve from 0.34791\n","Epoch 30/100\n","263/263 [==============================] - 22s 83ms/step - loss: 524.3900 - DistanceMetric: 0.3356 - val_loss: 499.2081 - val_DistanceMetric: 0.3292\n","\n","Epoch 00030: DistanceMetric did not improve from 0.34791\n","Epoch 31/100\n","263/263 [==============================] - 22s 83ms/step - loss: 465.7845 - DistanceMetric: 0.3313 - val_loss: 513.4617 - val_DistanceMetric: 0.3426\n","\n","Epoch 00031: DistanceMetric did not improve from 0.34791\n","Epoch 32/100\n","263/263 [==============================] - 22s 84ms/step - loss: 412.5392 - DistanceMetric: 0.3225 - val_loss: 338.2444 - val_DistanceMetric: 0.3527\n","\n","Epoch 00032: DistanceMetric did not improve from 0.34791\n","Epoch 33/100\n","263/263 [==============================] - 23s 86ms/step - loss: 364.0289 - DistanceMetric: 0.3187 - val_loss: 362.8519 - val_DistanceMetric: 0.3359\n","\n","Epoch 00033: DistanceMetric did not improve from 0.34791\n","Epoch 34/100\n","263/263 [==============================] - 22s 83ms/step - loss: 319.2675 - DistanceMetric: 0.3398 - val_loss: 314.4041 - val_DistanceMetric: 0.3270\n","\n","Epoch 00034: DistanceMetric did not improve from 0.34791\n","Epoch 35/100\n","263/263 [==============================] - 22s 83ms/step - loss: 279.4136 - DistanceMetric: 0.3294 - val_loss: 256.4567 - val_DistanceMetric: 0.3292\n","\n","Epoch 00035: DistanceMetric did not improve from 0.34791\n","Epoch 36/100\n","263/263 [==============================] - 22s 83ms/step - loss: 242.8787 - DistanceMetric: 0.3315 - val_loss: 202.8423 - val_DistanceMetric: 0.3426\n","\n","Epoch 00036: DistanceMetric did not improve from 0.34791\n","Epoch 37/100\n","263/263 [==============================] - 22s 83ms/step - loss: 210.3857 - DistanceMetric: 0.3294 - val_loss: 184.7814 - val_DistanceMetric: 0.3304\n","\n","Epoch 00037: DistanceMetric did not improve from 0.34791\n","Epoch 38/100\n","263/263 [==============================] - 22s 83ms/step - loss: 181.3756 - DistanceMetric: 0.3337 - val_loss: 164.9593 - val_DistanceMetric: 0.3225\n","\n","Epoch 00038: DistanceMetric did not improve from 0.34791\n","Epoch 39/100\n","263/263 [==============================] - 22s 84ms/step - loss: 155.6380 - DistanceMetric: 0.3344 - val_loss: 137.1985 - val_DistanceMetric: 0.3393\n","\n","Epoch 00039: DistanceMetric did not improve from 0.34791\n","Epoch 40/100\n","263/263 [==============================] - 22s 83ms/step - loss: 132.9308 - DistanceMetric: 0.3339 - val_loss: 157.8490 - val_DistanceMetric: 0.3248\n","\n","Epoch 00040: DistanceMetric did not improve from 0.34791\n","Epoch 41/100\n","263/263 [==============================] - 22s 84ms/step - loss: 113.5047 - DistanceMetric: 0.3441 - val_loss: 82.5313 - val_DistanceMetric: 0.3404\n","\n","Epoch 00041: DistanceMetric did not improve from 0.34791\n","Epoch 42/100\n","263/263 [==============================] - 22s 85ms/step - loss: 97.3389 - DistanceMetric: 0.3529 - val_loss: 99.7836 - val_DistanceMetric: 0.3571\n","\n","Epoch 00042: DistanceMetric improved from 0.34791 to 0.35290, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 43/100\n","263/263 [==============================] - 22s 84ms/step - loss: 84.2458 - DistanceMetric: 0.3610 - val_loss: 70.2469 - val_DistanceMetric: 0.3795\n","\n","Epoch 00043: DistanceMetric improved from 0.35290 to 0.36098, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 44/100\n","263/263 [==============================] - 22s 84ms/step - loss: 74.0547 - DistanceMetric: 0.3745 - val_loss: 50.6475 - val_DistanceMetric: 0.3750\n","\n","Epoch 00044: DistanceMetric improved from 0.36098 to 0.37452, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 45/100\n","263/263 [==============================] - 22s 83ms/step - loss: 66.3032 - DistanceMetric: 0.3862 - val_loss: 56.8156 - val_DistanceMetric: 0.3739\n","\n","Epoch 00045: DistanceMetric improved from 0.37452 to 0.38617, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 46/100\n","263/263 [==============================] - 22s 84ms/step - loss: 59.9404 - DistanceMetric: 0.4097 - val_loss: 55.3884 - val_DistanceMetric: 0.4196\n","\n","Epoch 00046: DistanceMetric improved from 0.38617 to 0.40970, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 47/100\n","263/263 [==============================] - 23s 87ms/step - loss: 55.0757 - DistanceMetric: 0.4268 - val_loss: 88.4638 - val_DistanceMetric: 0.4364\n","\n","Epoch 00047: DistanceMetric improved from 0.40970 to 0.42681, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 48/100\n","263/263 [==============================] - 22s 83ms/step - loss: 51.0132 - DistanceMetric: 0.4465 - val_loss: 65.0046 - val_DistanceMetric: 0.4554\n","\n","Epoch 00048: DistanceMetric improved from 0.42681 to 0.44653, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 49/100\n","263/263 [==============================] - 22s 84ms/step - loss: 47.6187 - DistanceMetric: 0.4715 - val_loss: 50.2432 - val_DistanceMetric: 0.4788\n","\n","Epoch 00049: DistanceMetric improved from 0.44653 to 0.47148, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 50/100\n","263/263 [==============================] - 22s 84ms/step - loss: 44.7540 - DistanceMetric: 0.4800 - val_loss: 38.6016 - val_DistanceMetric: 0.4989\n","\n","Epoch 00050: DistanceMetric improved from 0.47148 to 0.48004, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 51/100\n","263/263 [==============================] - 22s 84ms/step - loss: 42.2772 - DistanceMetric: 0.4995 - val_loss: 32.8999 - val_DistanceMetric: 0.4989\n","\n","Epoch 00051: DistanceMetric improved from 0.48004 to 0.49952, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 52/100\n","263/263 [==============================] - 22s 84ms/step - loss: 40.1553 - DistanceMetric: 0.5114 - val_loss: 63.4706 - val_DistanceMetric: 0.5413\n","\n","Epoch 00052: DistanceMetric improved from 0.49952 to 0.51141, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 53/100\n","263/263 [==============================] - 22s 84ms/step - loss: 38.3463 - DistanceMetric: 0.5252 - val_loss: 34.6509 - val_DistanceMetric: 0.5290\n","\n","Epoch 00053: DistanceMetric improved from 0.51141 to 0.52519, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 54/100\n","263/263 [==============================] - 22s 85ms/step - loss: 36.7518 - DistanceMetric: 0.5290 - val_loss: 32.2997 - val_DistanceMetric: 0.5290\n","\n","Epoch 00054: DistanceMetric improved from 0.52519 to 0.52899, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 55/100\n","263/263 [==============================] - 22s 84ms/step - loss: 35.3210 - DistanceMetric: 0.5383 - val_loss: 41.0128 - val_DistanceMetric: 0.5458\n","\n","Epoch 00055: DistanceMetric improved from 0.52899 to 0.53826, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 56/100\n","263/263 [==============================] - 22s 84ms/step - loss: 34.0863 - DistanceMetric: 0.5506 - val_loss: 28.3188 - val_DistanceMetric: 0.5446\n","\n","Epoch 00056: DistanceMetric improved from 0.53826 to 0.55062, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 57/100\n","263/263 [==============================] - 22s 85ms/step - loss: 33.3138 - DistanceMetric: 0.5430 - val_loss: 41.0369 - val_DistanceMetric: 0.5446\n","\n","Epoch 00057: DistanceMetric did not improve from 0.55062\n","Epoch 58/100\n","263/263 [==============================] - 23s 86ms/step - loss: 32.2344 - DistanceMetric: 0.5561 - val_loss: 24.6626 - val_DistanceMetric: 0.5580\n","\n","Epoch 00058: DistanceMetric improved from 0.55062 to 0.55608, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 59/100\n","263/263 [==============================] - 22s 84ms/step - loss: 31.4486 - DistanceMetric: 0.5649 - val_loss: 36.4198 - val_DistanceMetric: 0.5837\n","\n","Epoch 00059: DistanceMetric improved from 0.55608 to 0.56488, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 60/100\n","263/263 [==============================] - 22s 83ms/step - loss: 30.6463 - DistanceMetric: 0.5646 - val_loss: 34.8417 - val_DistanceMetric: 0.5837\n","\n","Epoch 00060: DistanceMetric did not improve from 0.56488\n","Epoch 61/100\n","263/263 [==============================] - 23s 88ms/step - loss: 29.9691 - DistanceMetric: 0.5763 - val_loss: 24.9922 - val_DistanceMetric: 0.5993\n","\n","Epoch 00061: DistanceMetric improved from 0.56488 to 0.57628, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 62/100\n","263/263 [==============================] - 22s 84ms/step - loss: 29.5925 - DistanceMetric: 0.5739 - val_loss: 29.5224 - val_DistanceMetric: 0.5960\n","\n","Epoch 00062: DistanceMetric did not improve from 0.57628\n","Epoch 63/100\n","263/263 [==============================] - 22s 85ms/step - loss: 29.0326 - DistanceMetric: 0.5848 - val_loss: 35.3941 - val_DistanceMetric: 0.5770\n","\n","Epoch 00063: DistanceMetric improved from 0.57628 to 0.58484, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 64/100\n","263/263 [==============================] - 23s 86ms/step - loss: 28.6097 - DistanceMetric: 0.5803 - val_loss: 27.3363 - val_DistanceMetric: 0.5848\n","\n","Epoch 00064: DistanceMetric did not improve from 0.58484\n","Epoch 65/100\n","263/263 [==============================] - 23s 86ms/step - loss: 28.4858 - DistanceMetric: 0.5817 - val_loss: 36.0814 - val_DistanceMetric: 0.5837\n","\n","Epoch 00065: DistanceMetric did not improve from 0.58484\n","Epoch 66/100\n","263/263 [==============================] - 22s 85ms/step - loss: 28.1644 - DistanceMetric: 0.5932 - val_loss: 24.1321 - val_DistanceMetric: 0.5982\n","\n","Epoch 00066: DistanceMetric improved from 0.58484 to 0.59316, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 67/100\n","263/263 [==============================] - 22s 86ms/step - loss: 27.5688 - DistanceMetric: 0.6122 - val_loss: 29.3130 - val_DistanceMetric: 0.6027\n","\n","Epoch 00067: DistanceMetric improved from 0.59316 to 0.61217, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 68/100\n","263/263 [==============================] - 23s 86ms/step - loss: 27.4699 - DistanceMetric: 0.6024 - val_loss: 26.2258 - val_DistanceMetric: 0.6161\n","\n","Epoch 00068: DistanceMetric did not improve from 0.61217\n","Epoch 69/100\n","263/263 [==============================] - 23s 87ms/step - loss: 27.6146 - DistanceMetric: 0.5972 - val_loss: 25.3107 - val_DistanceMetric: 0.5837\n","\n","Epoch 00069: DistanceMetric did not improve from 0.61217\n","Epoch 70/100\n","263/263 [==============================] - 23s 86ms/step - loss: 27.4662 - DistanceMetric: 0.6005 - val_loss: 26.3464 - val_DistanceMetric: 0.6205\n","\n","Epoch 00070: DistanceMetric did not improve from 0.61217\n","Epoch 71/100\n","263/263 [==============================] - 23s 87ms/step - loss: 26.8667 - DistanceMetric: 0.6129 - val_loss: 25.8391 - val_DistanceMetric: 0.6272\n","\n","Epoch 00071: DistanceMetric improved from 0.61217 to 0.61288, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 72/100\n","263/263 [==============================] - 23s 87ms/step - loss: 26.8637 - DistanceMetric: 0.6119 - val_loss: 30.1955 - val_DistanceMetric: 0.6161\n","\n","Epoch 00072: DistanceMetric did not improve from 0.61288\n","Epoch 73/100\n","263/263 [==============================] - 23s 86ms/step - loss: 27.1195 - DistanceMetric: 0.6062 - val_loss: 23.5411 - val_DistanceMetric: 0.6272\n","\n","Epoch 00073: DistanceMetric did not improve from 0.61288\n","Epoch 74/100\n","263/263 [==============================] - 23s 88ms/step - loss: 26.6883 - DistanceMetric: 0.6155 - val_loss: 30.9483 - val_DistanceMetric: 0.5960\n","\n","Epoch 00074: DistanceMetric improved from 0.61288 to 0.61549, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 75/100\n","263/263 [==============================] - 23s 86ms/step - loss: 26.6211 - DistanceMetric: 0.6172 - val_loss: 25.2870 - val_DistanceMetric: 0.6540\n","\n","Epoch 00075: DistanceMetric improved from 0.61549 to 0.61716, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 76/100\n","263/263 [==============================] - 22s 84ms/step - loss: 26.6525 - DistanceMetric: 0.6169 - val_loss: 28.8000 - val_DistanceMetric: 0.6172\n","\n","Epoch 00076: DistanceMetric did not improve from 0.61716\n","Epoch 77/100\n","263/263 [==============================] - 22s 83ms/step - loss: 26.2386 - DistanceMetric: 0.6271 - val_loss: 28.2408 - val_DistanceMetric: 0.5993\n","\n","Epoch 00077: DistanceMetric improved from 0.61716 to 0.62714, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 78/100\n","263/263 [==============================] - 22s 83ms/step - loss: 26.1539 - DistanceMetric: 0.6191 - val_loss: 36.0482 - val_DistanceMetric: 0.6004\n","\n","Epoch 00078: DistanceMetric did not improve from 0.62714\n","Epoch 79/100\n","263/263 [==============================] - 22s 83ms/step - loss: 26.1543 - DistanceMetric: 0.6233 - val_loss: 22.7553 - val_DistanceMetric: 0.6295\n","\n","Epoch 00079: DistanceMetric did not improve from 0.62714\n","Epoch 80/100\n","263/263 [==============================] - 22s 83ms/step - loss: 26.1145 - DistanceMetric: 0.6219 - val_loss: 25.7507 - val_DistanceMetric: 0.6239\n","\n","Epoch 00080: DistanceMetric did not improve from 0.62714\n","Epoch 81/100\n","263/263 [==============================] - 22s 83ms/step - loss: 26.1021 - DistanceMetric: 0.6293 - val_loss: 21.5819 - val_DistanceMetric: 0.6105\n","\n","Epoch 00081: DistanceMetric improved from 0.62714 to 0.62928, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 82/100\n","263/263 [==============================] - 22s 83ms/step - loss: 25.7371 - DistanceMetric: 0.6317 - val_loss: 26.7392 - val_DistanceMetric: 0.6071\n","\n","Epoch 00082: DistanceMetric improved from 0.62928 to 0.63165, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 83/100\n","263/263 [==============================] - 22s 83ms/step - loss: 25.7729 - DistanceMetric: 0.6357 - val_loss: 26.2337 - val_DistanceMetric: 0.6562\n","\n","Epoch 00083: DistanceMetric improved from 0.63165 to 0.63569, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 84/100\n","263/263 [==============================] - 22s 82ms/step - loss: 25.9052 - DistanceMetric: 0.6352 - val_loss: 21.3981 - val_DistanceMetric: 0.6395\n","\n","Epoch 00084: DistanceMetric did not improve from 0.63569\n","Epoch 85/100\n","263/263 [==============================] - 22s 82ms/step - loss: 25.8119 - DistanceMetric: 0.6324 - val_loss: 19.8383 - val_DistanceMetric: 0.6518\n","\n","Epoch 00085: DistanceMetric did not improve from 0.63569\n","Epoch 86/100\n","263/263 [==============================] - 22s 83ms/step - loss: 25.4553 - DistanceMetric: 0.6419 - val_loss: 23.4470 - val_DistanceMetric: 0.6350\n","\n","Epoch 00086: DistanceMetric improved from 0.63569 to 0.64187, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 87/100\n","263/263 [==============================] - 22s 83ms/step - loss: 25.4098 - DistanceMetric: 0.6450 - val_loss: 36.2097 - val_DistanceMetric: 0.6250\n","\n","Epoch 00087: DistanceMetric improved from 0.64187 to 0.64496, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 88/100\n","263/263 [==============================] - 22s 85ms/step - loss: 25.4566 - DistanceMetric: 0.6302 - val_loss: 26.9382 - val_DistanceMetric: 0.6339\n","\n","Epoch 00088: DistanceMetric did not improve from 0.64496\n","Epoch 89/100\n","263/263 [==============================] - 22s 84ms/step - loss: 25.3140 - DistanceMetric: 0.6407 - val_loss: 26.4397 - val_DistanceMetric: 0.6261\n","\n","Epoch 00089: DistanceMetric did not improve from 0.64496\n","Epoch 90/100\n","263/263 [==============================] - 22s 83ms/step - loss: 25.3446 - DistanceMetric: 0.6326 - val_loss: 21.0072 - val_DistanceMetric: 0.6138\n","\n","Epoch 00090: DistanceMetric did not improve from 0.64496\n","Epoch 91/100\n","263/263 [==============================] - 22s 83ms/step - loss: 25.1135 - DistanceMetric: 0.6476 - val_loss: 24.7443 - val_DistanceMetric: 0.6507\n","\n","Epoch 00091: DistanceMetric improved from 0.64496 to 0.64758, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 92/100\n","263/263 [==============================] - 22s 83ms/step - loss: 25.2118 - DistanceMetric: 0.6473 - val_loss: 25.1687 - val_DistanceMetric: 0.6161\n","\n","Epoch 00092: DistanceMetric did not improve from 0.64758\n","Epoch 93/100\n","263/263 [==============================] - 22s 83ms/step - loss: 25.3951 - DistanceMetric: 0.6317 - val_loss: 26.7399 - val_DistanceMetric: 0.6484\n","\n","Epoch 00093: DistanceMetric did not improve from 0.64758\n","Epoch 94/100\n","263/263 [==============================] - 22s 83ms/step - loss: 24.8899 - DistanceMetric: 0.6500 - val_loss: 24.4375 - val_DistanceMetric: 0.6473\n","\n","Epoch 00094: DistanceMetric improved from 0.64758 to 0.64995, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 95/100\n","263/263 [==============================] - 22s 83ms/step - loss: 24.9430 - DistanceMetric: 0.6464 - val_loss: 20.2747 - val_DistanceMetric: 0.6674\n","\n","Epoch 00095: DistanceMetric did not improve from 0.64995\n","Epoch 96/100\n","263/263 [==============================] - 22s 85ms/step - loss: 24.7392 - DistanceMetric: 0.6554 - val_loss: 23.5524 - val_DistanceMetric: 0.6440\n","\n","Epoch 00096: DistanceMetric improved from 0.64995 to 0.65542, saving model to /content/drive/My Drive/Colab Notebooks/pretrained_weights/rbf_model.h5\n","Epoch 97/100\n","207/263 [======================>.......] - ETA: 4s - loss: 24.8904 - DistanceMetric: 0.6522"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":358},"id":"rdcsi0czLiYT","executionInfo":{"status":"error","timestamp":1610905614454,"user_tz":360,"elapsed":952,"user":{"displayName":"Hunter Wang","photoUrl":"","userId":"00316085319183830862"}},"outputId":"c3075d3b-7026-47e2-8445-110f261d7a2f"},"source":["results = rbf_model.reject(x_test)\n","print(results)\n","# print(sum(results[0][:10]))\n","# print(results.shape)"],"execution_count":12,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-2c3b1e604c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(sum(results[0][:10]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(results.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-21845b6cfd0e>\u001b[0m in \u001b[0;36mreject\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misAnomalyDetector\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot reject a softmax classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRBF_LAMBDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mOk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected images to have 5 dimensions, but got array with shape (908, 66, 200, 3)"]}]},{"cell_type":"markdown","metadata":{"id":"AjojTDNKC4g9"},"source":["## Explore the effects of changing the opacity of the attack"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"AKzxkxWTqYJd"},"source":["model = rbf_model\n","alphas = np.linspace(0,1,50)\n","maxConfidence = np.zeros((6,len(alphas),20))\n","maxConfidence.fill(-1)\n","i = 0\n","classes = [0,1,2,7,8,9]\n","for alpha in alphas:\n","    xadv,y_adv,y_label,x_clean = PhysicalAttackLanes(alpha)\n","    prediction_rejection = model.reject(xadv)\n","    for j in range(len(classes)):\n","        idx = np.argmax(y_label,axis=1)==classes[j]\n","        maxConfidence[j,i,:] = prediction_rejection[idx]\n","    i += 1\n","    print('Progress',i,'/',len(alphas))\n","\n","#plt.rcParams['text.uselatex'] = True\n","plt.title(\"Effects of Increasing the Opacity of the Anomaly\",fontsize=16,pad=20)\n","plt.xlabel(r'$\\alpha $',fontsize=14)\n","plt.ylabel(\"Average Probability of Rejection Class\",fontsize=14)\n","for j in range(len(classes)):\n","    mu = np.mean(maxConfidence[j],axis=1)\n","    std = np.std(maxConfidence[j],axis=1)\n","    plt.errorbar(alphas,mu,label=str(classes[j]),yerr=std,elinewidth=0.5,errorevery=3)\n","\n","plt.tick_params(axis='both',labelsize=12)\n","plt.legend(title='Ground Truth',loc='lower right',prop={'size': 12})\n","plt.savefig('/content/drive/My Drive/Colab Notebooks/Effects_Of_Modifying_Alpha.eps', format='eps', dpi=1000,bbox_inches='tight')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-zfOZcPDPiU"},"source":["## Define show the shift in confidence on the attack images"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"2HhcT6LTxhyr"},"source":["x_test,y_test = test_data_generator.next()\n","print('Number of test data',y_test.shape[0])\n","xadv,yadv,y_true,x_clean = PhysicalAttackLanes()\n","P1 = rbf_model.reject(x_test)\n","Y1=y_test\n","P2=rbf_model.reject(xadv)\n","Y2=yadv\n","title = 'DAVE-II RBF Probability of Rejection Class'\n","showMax=False\n","showRejection = True\n","numGraphs = 2\n","thresh = 0.05\n","plt.figure()\n","if showRejection:\n","    confidence = P1\n","elif showMax:\n","    confidence = P1[np.arange(P1.shape[0]),np.argmax(P1,axis=1)]\n","else:\n","    confidence = P1[np.arange(P1.shape[0]),np.argmax(Y1,axis=1)]\n","\n","perc = np.percentile(confidence,90)\n","#print('95th Percentile: ', perc)\n","print(title)\n","print('Clean data less than', str(thresh),': ',end='')\n","print(np.sum(confidence<thresh)/len(confidence))\n","#print(np.sum(np.bitwise_and(confidence<0.5,np.argmax(P1,axis=1) == np.argmax(Y1,axis=1))))\n","plt.hist(confidence,bins=20,density=1,label='Clean Data',color='mediumblue', edgecolor='black', linewidth=0.7)\n","if numGraphs==2:\n","    if showRejection:\n","        confidence = P2\n","    elif showMax:\n","        confidence = P2[np.arange(P2.shape[0]),np.argmax(P2,axis=1)]\n","    else:\n","        confidence = P2[np.arange(P2.shape[0]),np.argmax(Y2,axis=1)]\n","    if (showMax or showRejection): # daveii analysis\n","        label = 'OOD Data'\n","    else:\n","        label = 'Backdoor Data'\n","    plt.hist(confidence,bins=20,density=1,label=label,color='firebrick', edgecolor='black', linewidth=0.7)\n","    perc = np.percentile(confidence,90)\n","    #print('95th Percentile: ', perc)\n","    print('Dirty data less than', str(thresh),': ',end='')\n","    print(np.sum(confidence<thresh)/len(confidence))\n","    print('\\n')\n","    plt.title(title,fontsize=16,pad=20)\n","    plt.tick_params(axis='both',labelsize=12)\n","    plt.legend(loc='best',prop={'size': 12})\n","    plt.xlabel('Probability',fontsize=14)\n","    plt.ylabel('Density',fontsize=14)\n","    plt.savefig('/content/DaveII_RBF_Test_Confidence.eps', format='eps', dpi=1000,bbox_inches='tight')\n","    title = title.replace(' ','_')\n","    plt.show()\n","    #plt.savefig(os.path.join('./images',title))\n","    #plt.savefig(os.path.join('./AdversarialDefense/src/images',title))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBstiyhOEKi_"},"source":["# DAVEII Regression\n","The following is utility function to load the regression data set into a numpy array that can be used by keras, tensorflow, or pytorch with custom data loaders"]},{"cell_type":"markdown","metadata":{"id":"7QEjymHZF6z-"},"source":["## A Function to read in a DAVEII Data set"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"dtOApcz9EWIn"},"source":["#DataSetLoader.py\n","#Authored: Matthew Burruss\n","#Last Edited: 3/28/2019\n","#Description: Provides functions for loading inputs and outputs from datasets contained in csv files\n","import numpy as np\n","import random\n","import csv\n","\n","def load_input(pathToFile):\n","    # initialize loop variables\n","    inputs = []\n","    Y = []\n","    if not os.path.isfile(pathToFile):\n","        print(\"File not found.\")\n","        return\n","    # read images in ProcessData.csv and append to input\n","    print('Reading inputs...')\n","    with open(pathToFile, 'rt') as csvfile:\n","        reader = csv.reader(csvfile)\n","        list = []\n","        rownum = 1\n","        img_num = -1\n","        images_processed = 0\n","        for row in reader:\n","            if (images_processed == img_num):\n","                break\n","            if (rownum == 1):\n","                img_num = int(row[0])\n","                rownum = rownum + 1\n","                continue\n","            else:\n","                list.append(row)\n","            # every other row: get the images (each image is spread 13200x3 in excel)\n","            if ((rownum-1) %3 == 0):\n","                img = np.asarray(list,dtype=np.uint8)\n","                img = np.resize(img,(66,200,3))\n","                inputs.append(img)\n","                list = []\n","                images_processed = images_processed + 1\n","            rownum = rownum + 1\n","    return np.array(inputs)\n","\n","def load_output(pathToFile):\n","    # initialize loop variables\n","    Steering=[]\n","    Acceleration=[]\n","    if not os.path.isfile(pathToFile):\n","        print(\"File not found.\")\n","        return\n","    # read images in ProcessData.csv and append to input\n","    print('Reading outputs...')\n","    with open(pathToFile, 'rt') as csvfile:\n","        reader = csv.reader(csvfile)\n","        rownum = 1\n","        for row in reader:\n","            if (rownum == 1):\n","                img_num = int(row[0])\n","                rownum = rownum + 1\n","                continue\n","            # steering duty cycles\n","            if (rownum == img_num*3+4):\n","                for steering in row:\n","                    output = []\n","                    y=(float(steering)-10.0)/(20.0-10.0)\n","                    output.append(y)\n","                    Steering.append(output)\n","            # acc duty cycles\n","            elif (rownum == img_num*3+3):\n","                for acc in row:\n","                    output = []\n","                    acc=(float(acc)-10.0)/(20.0-10.0)\n","                    output.append(acc)\n","                    Acceleration.append(output)\n","            rownum = rownum + 1\n","    steer = np.array(Steering)\n","    acc = np.array(Acceleration)\n","    return np.concatenate((steer,acc),axis=1)\n","\n","\n","X = load_input(PATH_TO_REGRESSION_CSV)\n","Y = load_output(PATH_TO_REGRESSION_CSV)\n","# normalize X\n","X = X/255.\n","\n","print('X shape: ',X.shape)\n","print('Y.shape: ',Y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zxBuFAwjKEw3"},"source":["plt.imshow(X[0])\n","plt.show()"],"execution_count":null,"outputs":[]}]}